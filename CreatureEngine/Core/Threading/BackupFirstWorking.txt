CPP=======================================================
#include"Threadpool.h"


/*

https://www.youtube.com/watch?v=zULU6Hhp42w&list=PLl8Qc2oUMko_FMAaK7WY4ly0ikLFrYCE3&index=4

*/
#define SLEEP_TIME 1
std::atomic<int> Function_Counter{ 0 };

namespace Core
{
	namespace Threading
	{
#ifdef MY_WRAPPER
		bool JobQueue::Try_Pop(Worker_Function*& func)
		{/* Try to aquire a function off the Queue to run */
			std::unique_lock<std::mutex> Lock{ QueueMutex, std::try_to_lock };
			if (!Lock || TaskQueue.empty())
			{
				return false;
			}
			//	func = std::move(TaskQueue.front());
			//	TaskQueue.pop_front();
			func = std::move(TaskQueue.front());//std::forward(TaskQueue.front());// std::move(
			TaskQueue.pop_front();/// IF this exist program crashes and freezes up....
			return true;
		}

		/* Aquires the front of the Task Queue */
		bool JobQueue::pop(Worker_Function*& func)
		{
			std::unique_lock<std::mutex> Lock{ QueueMutex };
			while (TaskQueue.empty() && !is_Done)
			{/* If there is no work and we are not done wait for notification that work is to be done */
				is_Ready.wait(Lock);
			}
			if (TaskQueue.empty())
			{/* If task is empty and we are done return false so thread pool knows to break out of Run loop */
				return false;
			}
			func = std::move(TaskQueue.front());
			TaskQueue.pop_front();
			return true;
		}
#else
		bool JobQueue::Try_Pop(Worker_Function &func)
		{/* Try to aquire a function off the Queue to run */
			std::unique_lock<std::mutex> Lock{ QueueMutex, std::try_to_lock };
			if (!Lock || TaskQueue.empty())
			{
				return false;
			}
		 //	func = std::move(TaskQueue.front());
		 //	TaskQueue.pop_front();
			return true;
		}
		bool JobQueue::pop(Worker_Function &func)
		{
			std::unique_lock<std::mutex> Lock{ QueueMutex };
			while (TaskQueue.empty() && !is_Done)
			{
				is_Ready.wait(Lock);
			}
			if (TaskQueue.empty())
			{
				return false;
			}
		 	func = std::move(TaskQueue.front());//std::forward(TaskQueue.front());// std::move(
			TaskQueue.pop_front();
			return true;
		}
#endif

		/* Signal to the Threadpool it is time to destroy this queue and shut down its thread */
		void JobQueue::Done()
		{
			{
				std::unique_lock<std::mutex> Lock{ QueueMutex };
				is_Done = true;
			}
			is_Ready.notify_all();
		}

		ThreadPool::ThreadPool()
		{/* Spawn N worker Threads all executing the Run method */
			for (int N{ 0 }; N < ThreadCount; ++N)
			{
				Worker_Threads.emplace_back([&, N] {Run(N); });
			}
		}
		ThreadPool::~ThreadPool()
		{
			for (auto& Q : ThreadQueue)
			{
				Q.Done();
			}
			for (auto& WT : Worker_Threads)
			{
				WT.join();
			}
		}
// { nullptr };// = new Wrapper_Base();
#ifdef MY_WRAPPER
		void ThreadPool::Run(unsigned int _i)
		{
			while (true)
			{/* Constant loop which we break out of when the Queue triggers an exit */
				Worker_Function* Func{ nullptr }; 
				for (unsigned int N{ 0 }; N != ThreadCount; ++N)
				{
					if (ThreadQueue[static_cast<size_t>((_i + N) % ThreadCount)].Try_Pop(Func))
					{
						break;
					}
				}
				if (!Func && !ThreadQueue[_i].pop(Func)) 
				{
					break; // Possibly need this to be a continue
				}
				Func->Invoke();
			}
		}
#else
		void ThreadPool::Run(unsigned int _i)
		{
			while (true)
			{
				Worker_Function Func;
				for (unsigned int N{ 0 }; N != ThreadCount; ++N)
				{
					if (ThreadQueue[static_cast<size_t>((_i + N) % ThreadCount)].Try_Pop(Func))
					{
						break;
					}
				}
				if (!ThreadQueue[_i].pop(Func))//!Func && 
				{
					break; // Possibly need this to be a continue
				}
				Func();
			}
		}
#endif
	}// End NS Threading
}// End NS Core


//EXACT CODE
/*
void run(unsigned i)
{
	while (true) {
		function<void()> f;

		for (unsigned n = 0; n != _count; ++n)
		{
			if (_q[(i + n) % _count].try_pop(f))break;
		}
		if (!f && !_q[i].pop(f))break;
		f();
	}


template<typename F>
void async(F&& f)
{
	auto i = _index++;
	for (unsigned n = 0; n != _count ++n) {
		if (_q[(i + n) % _count].try_push(forward, F(f))) return;
	}
	_q[i % _count].push(forward<F>(f));
}

template<typename F>
bool try_push(F&& f)
{
	{
		lock_t lock(_mutex, try_to_lock);
		if (!lock)return false;
		_q.emplace_back(forward<F>(f));
	}
	_ready.notify_one();
	return true;
}


bool try_pop(function<void()>& x)
{
	lock_t lock(_mutex, try_to_lock);
	if (!lock || _q.empty()) return false;
	x = move(_q.front());
	_q.pop_front();
	return true
}

*/








#include<iostream>
#include<string>

#pragma optimize( "", off )
/* unoptimized code section */
#define Worker_Print(x) //std::cout << x << " : "


OPTIMIZATION_OFF()
void TestFunction(int _count, int _output)
{
	int result{ 0 };
	for (int i{ 0 }; i < _count; ++i)
	{
		result++;
		result += std::pow(result, _output);
	}
	std::cout << "PARAM:" << _output << "Finished Work: " << result << "\n";
}
OPTIMIZATION_ON()


OPTIMIZATION_OFF()
int TestFunctionA()
{
	Worker_Print( "FunctionA");
	Sleep(SLEEP_TIME);
	++Function_Counter;
	return 11;
}
OPTIMIZATION_ON()


OPTIMIZATION_OFF()
int TestFunctionB(int _param)
{
	int result;
	Worker_Print("FunctionB: " << _param) ;
	//result.set_value(10);
	result = _param * 2;
	Sleep(SLEEP_TIME);
++Function_Counter;
	return result;
}
OPTIMIZATION_ON()

OPTIMIZATION_OFF()
float TestFunctionC(float _paramA, int _paramB)
{
	Worker_Print("FunctionC: " << _paramA << " : " << _paramB );
	Sleep(SLEEP_TIME);
	++Function_Counter;
	return _paramA * _paramB;
}
OPTIMIZATION_ON()

OPTIMIZATION_OFF()
std::string TestFunctionD(float _paramA, int _paramB)
{
	Worker_Print("FunctionD " << _paramA << " : " << _paramB );
	Sleep(SLEEP_TIME);
	++Function_Counter;
	return "String: " + std::to_string(_paramA) + " : " + std::to_string(_paramB);
}
OPTIMIZATION_ON()

OPTIMIZATION_OFF()
std::vector<uint32_t> TestFunctionE(int _paramA)
{
	std::vector<uint32_t> SomethingAllocated;

	uint64_t result{ 0 };
	for (int i{ 0 }; i < _paramA; ++i)
	{
		//	std::cout << "E: " << i*i ;
		result += i * i;
		SomethingAllocated.push_back(result);
	}
	Sleep(SLEEP_TIME);
	++Function_Counter;
	return SomethingAllocated;
}
OPTIMIZATION_ON()

OPTIMIZATION_OFF()
std::vector<uint32_t> TestFunctionF(int _paramA)
{
	std::vector<uint32_t> SomethingAllocated;
	uint64_t result{ 0 };
	for (int i{ 0 }; i < _paramA; ++i)
	{
		double A = sqrt(i*i);
		//		std::cout << "F: " << A ;
		result += _paramA * i + A;
		SomethingAllocated.push_back(result);
	}	
	Sleep(SLEEP_TIME);
	++Function_Counter;
	return SomethingAllocated;
}
OPTIMIZATION_ON()


OPTIMIZATION_OFF()
std::vector<uint32_t> TestFunctionG(int _paramA)
{
	std::vector<uint32_t> SomethingAllocated;
	uint64_t result{ 0 };
	int B = rand() % _paramA;
	int C{ 0 };

	for (int i{ 0 }; i < _paramA; ++i)
	{
		double A = sqrt(i*i);
		//		std::cout << "G: " << A ;
		result += (_paramA * i) / pow(A, i);
		SomethingAllocated.push_back(result);
	}
	Sleep(SLEEP_TIME);
	++Function_Counter;
	return SomethingAllocated;
}
OPTIMIZATION_ON()

OPTIMIZATION_OFF()
std::vector<uint32_t> TestFunctionH(int _paramA)
{
	std::vector<uint32_t> SomethingAllocated;
	double A{ 0 };
	uint64_t result{ 0 };
	int B = rand() % _paramA;
	int C{ 0 };

	for (int i{ 0 }; i < _paramA; ++i)
	{
		A = sqrt(i*i);
	    Worker_Print( "H: " << A );
		result += i * A;
		SomethingAllocated.push_back(result);
	}
	Sleep(SLEEP_TIME);
	++Function_Counter;
	return SomethingAllocated;
}
OPTIMIZATION_ON()

OPTIMIZATION_OFF()
std::vector<uint32_t> TestFunctionI(int _paramA)
{
	std::vector<uint32_t> SomethingAllocated;
	uint64_t A{ 0 };

	int B = rand() % _paramA;
	int C{ 0 };

	for (int i{ 0 }; i < _paramA; ++i)
	{
		A = pow(_paramA, i);
		if (!((i+1) % (B+1)))C += A;
		Worker_Print( "I: " << A );	
		uint32_t result = A * C;
		SomethingAllocated.push_back(result);
	}
	Sleep(SLEEP_TIME);
	++Function_Counter;
	return SomethingAllocated;
}
OPTIMIZATION_ON()

OPTIMIZATION_OFF()
std::vector<uint32_t> TestFunctionJ(int _paramA)
{
	std::vector<uint32_t> SomethingAllocated;
	float A = 0;
	int B = rand() % _paramA;
	int C{ 0 };
	for (int i{ 0 }; i < _paramA; ++i)
	{
		A = pow(i, _paramA) / i;
		if (A == B)C = i;
		Worker_Print("J: " << A << ":");
		uint32_t result = A * C;
		SomethingAllocated.push_back(result);
	}
	Sleep(SLEEP_TIME);
	++Function_Counter;
	return SomethingAllocated;
}
OPTIMIZATION_ON()

OPTIMIZATION_OFF()
uint64_t Worker_TestFunction(size_t _count)
{
	int B = rand() % _count;
	int C{ 0 };
	for(uint32_t i{0}; i< _count; ++i)
	{
		std::cout << i << ":";
		if (!((i+1) % (B+1)))C++;
	}
	return _count * C;
}
OPTIMIZATION_ON()

OPTIMIZATION_OFF()
uint64_t TestCompile(std::vector<std::vector<uint32_t>> _input)
{
	uint64_t result{ 0 };
	for (auto& Y : _input)
	{
		for (auto& X : Y)
		{
			result += X;
		}
	}
	return result;
}
OPTIMIZATION_ON()



OPTIMIZATION_OFF()

template<typename T, typename N, typename O>
T power(T x, N n, O op)
{
	if (n == 0) return op;//identity_element(op);

	while ((n & 1) == 0) {
		n > 1;
		x = op(x, x);
	}
	T result = x;
	n >>= 1;
	while (n != 0)
	{
		x = op(x, x);
		if ((n & 1) != 0) result = op(result, x);
		n >> 1;
	}
	return result;
}

OPTIMIZATION_ON()

/*NOTES:

Faster STD::FUNCTION Implementation
https://github.com/skarupke/std_function/blob/master/function.h


Lock Free Ring Buffer
https://github.com/tempesta-tech/blog/blob/master/lockfree_rb_q.cc

Lock-Free Programming
https://www.cs.cmu.edu/~410-s05/lectures/L31_LockFree.pdf

A Fast Lock-Free Queue for C++
http://moodycamel.com/blog/2013/a-fast-lock-free-queue-for-c++

Introduction to Multithreaded Algorithms
http://ccom.uprrp.edu/~ikoutis/classes/algorithms_12/Lectures/MultithreadedAlgorithmsApril23-2012.pdf

A Thread Pool with C++11
http://progsch.net/wordpress/?p=81

Parallelizing the Naughty Dog Engine
https://www.gdcvault.com/play/1022186/Parallelizing-the-Naughty-Dog-Engine

C++11 threads, affinity and hyperthreading
https://eli.thegreenplace.net/2016/c11-threads-affinity-and-hyperthreading/

Thread pool worker implementation
https://codereview.stackexchange.com/questions/60363/thread-pool-worker-implementation

Thread pool implementation using c++11 threads
https://github.com/mtrebi/thread-pool

C++11 Multithreading – Part 8: std::future , std::promise and Returning values from Thread
https://thispointer.com/c11-multithreading-part-8-stdfuture-stdpromise-and-returning-values-from-thread/


CppCon 2015: Fedor Pikus PART 2 “Live Lock-Free or Deadlock (Practical Lock-free Programming) ”
Queue
https://www.youtube.com/watch?v=1obZeHnAwz4&t=3055s


Thread Pool Implementation on Github:
https://github.com/mtrebi/thread-pool/blob/master/README.md#queue

Threadpool with documentation:
https://www.reddit.com/r/cpp/comments/9lvji0/c_threadpool_with_documentation/

Original White paper on Work stealing Queues:
http://supertech.csail.mit.edu/papers/steal.pdf

Code overview - Thread Pool & Job System
https://www.youtube.com/watch?v=Df-6ws_EZno

while(running)
{
    Try to Lock and return True or False
	True:
	False: Push it to 
}


===========================================================

HEADER
===============================================================

#pragma once
#include <thread>
#include <functional>
#include <future>
#include <deque>
#include <queue>
#include <array>
#include <tuple>

#include<Windows.h>
#include"Core\Common.h"
#include<iostream>

#define MY_WRAPPER

/// template<typename Function, typename ...Args>
/// result_type = std::result_of_t<std::decay_t<Function>(std::decay_t<Args>...)>;

extern std::atomic<int> Function_Counter;
//https://code.woboq.org/llvm/libcxx/include/type_traits.html
//std::future<int>
/// Use this switch with Compiler Explorer inorder to allow it to compile: -std=c++17 -O3
struct Wrapper_Base
{/// __declspec(novtable) USE THIS
	virtual void Invoke() noexcept = 0;
	void operator()() noexcept
	{
		Invoke();
	}
	/* Implement a Then, When_all and Deferred Function handling */
};

template<typename _Func, typename ...ARGS>
struct Wrapper : Wrapper_Base
{
	using type = std::invoke_result_t<_Func&, ARGS...>;
	using reference_type = type&;
	using Fptr = type(*)(ARGS...);

	Fptr Function;
	std::tuple<ARGS...> Arguments;
	std::promise<type> ReturnValue;
	Wrapper(_Func&& _function, ARGS&&... _args) noexcept
		:
		Function(std::move(_function)),
		Arguments(std::forward<ARGS>(_args)...)
	{}

	Wrapper(Wrapper&& _other) noexcept
		:
		Function(std::move(_other.Function)),
		Arguments(std::forward<ARGS>(_other.Arguments)),
		ReturnValue(std::move(_other.ReturnValue))
	{
		std::cout << "Called the Forward Function" << "\n";
	}
	Wrapper& operator==(Wrapper&& _other) noexcept
	{
		Function = std::move(_other.Function);
		Arguments = std::forward<ARGS>(_other.Arguments);
		ReturnValue = std::move(_other.ReturnValue);
		std::cout << "Called Assignment Operator " << "\n";
	}

	virtual void Invoke() noexcept override
	{
		 auto result = std::apply(Function, Arguments);
 		 ReturnValue.set_value(result);
	}
};


#ifdef MY_WRAPPER
    typedef Wrapper_Base Worker_Function;
#else
    typedef std::function<void()> Worker_Function;
#endif

template<typename _Ty, size_t _SZ>
class ring_buffer
{
public:
	using value_type = _Ty;
	using reference = _Ty & ;
	using pointer = const _Ty*;

	ring_buffer() = default;

	bool push_back(reference _element)
	{/// Just deferring this function to make it compatible with older Queue system for Threadpool
		return push(_element);
	}
	bool push(reference _element)
	{// Adds new Element to Queue
		std::atomic<size_t> OldWritePosition;/// = WritePosition.load();
		std::atomic<size_t> NewWritePosition = NextElement(OldWritePosition);
		if (NewWritePosition)/// == ReadPosition.load())
		{/* If Read position and Write position are the same Buffer is Full */
			return false;
		}
///		Data[OldWritePosition] = _element;
		WritePosition = NewWritePosition;
	}

	/// WE MIGHT BE ABLE TO PACK THE READER AND WRITER INTO THE SAME ATOMIC INTEGER WHICH WILL REDUCE THE OVERHEAD
	bool pop(reference _returnElement)
	{/* Returns True if more elements in Queue*/
		while (true)
		{/* READER Multiple in Existance */
			std::atomic<size_t> OldReadPosition = ReadPosition.load();

			if (WritePosition.load() == OldReadPosition.load())
			{// If attempting to read the same position again or buffer is full return false;
				return false;
			}

			_returnElement = Data[OldReadPosition];// Perhaps std::move() would be better for performance
			if (ReadPosition.compare_exchange_strong(OldReadPosition, NextElement(OldReadPosition)))
			{
				return true;
			}
		}
	}

	auto front()
	{/// Possibly wrong currently a place holder to make the experimental ringbuffer compatible with older style of queue
		return &Data[ReadPosition];
	}
	void pop_front() 
	{/// Possibly wrong currently a place holder to make the experimental ringbuffer compatible with older style of queue
		WritePosition = NextElement(WritePosition);
	}
	bool empty()
	{/// Possibly wrong currently a place holder to make the experimental ringbuffer compatible with older style of queue
		return (ReadPosition == WritePosition);
	}

	reference operator[](const int _offset)
	{
		return Data[_offset]; //[ReadPosition % BufferSize];
	}

	bool destroy()
	{
		delete[](Data);
	}

	size_t size()
	{
		return BufferSize;
	}

private:

	std::array<std::atomic<_Ty*>, _SZ + 1> Data;

	size_t NextElement(size_t _pos)
	{
		return ++_pos == BufferSize ? 0 : _pos;
	}

	size_t
		ReadPosition{ 0 },
		WritePosition{ 0 };
	size_t Length, Size, Start, End, Elements;
	size_t BufferSize = _SZ + 1;
};


// NOTE: https://riptutorial.com/cplusplus/example/15806/create-a-simple-thread-pool
namespace Core
{
	namespace Threading
	{

		struct JobQueue
		{
		public:
			JobQueue() = default;

			std::condition_variable is_Ready;
			std::mutex QueueMutex;
			bool is_Done{ false };
			void Done();

#ifdef MY_WRAPPER

			std::deque<Worker_Function*> TaskQueue;

			bool Try_Pop(Worker_Function*& func);
			bool pop(Worker_Function*& func);

			/* Attempt to push a Worker onto the Task Queue fails if unable to aquire mutex else returns true */
			bool try_push(Worker_Function *func)
			{
				{
					std::unique_lock<std::mutex> Lock{ QueueMutex, std::try_to_lock };
					if (!Lock)
					{/* If our mutex is already locked simply return */
						return false;
					}
					/* Else place on the back of our Queue*/
					TaskQueue.push_back(std::move(func)); 
				}/* Unlock the Mutex */
				is_Ready.notify_one(); /* Tell the world about it */
				return true;/* Lets Async know it was successful and that it can return the future now */
			}
			void push(Worker_Function* func)
			{/* Adds a Function to our Queue */
				{
					std::unique_lock<std::mutex> Lock{ QueueMutex };
					TaskQueue.emplace_back(std::move(func));//std::move<_FUNC> std::forward<_FUNC&>(&((Worker_Function *)
				}
			}
		};
#else
			std::deque<Worker_Function> TaskQueue;

			bool Try_Pop(Worker_Function& func);
			bool pop(Worker_Function& func);
			template<typename _FUNC> bool try_push(_FUNC&& func)
			{
				{
					std::unique_lock<std::mutex> Lock{ QueueMutex, std::try_to_lock };
					if (!Lock)
					{/* If our mutex is already locked simply return */
						return false;
					}
					/* Else place on the back of our Queue*/
					TaskQueue.emplace_back(std::forward<_FUNC>(func));
				}
				is_Ready.notify_one();
				return true;
			}
			template<typename _FUNC> void push(_FUNC&& func)
			{/* Adds a Function to our Queue */
				{
					std::unique_lock<std::mutex> Lock{ QueueMutex };
					TaskQueue.emplace_back(std::forward<_FUNC>(func));//std::move<_FUNC> std::forward<_FUNC&>(&((Worker_Function *)
				}
			}
		};
#endif
		class ThreadPool
		{
			const unsigned int ThreadCount{  std::thread::hardware_concurrency() -1};
			std::vector<std::thread> Worker_Threads;
			std::vector<JobQueue> ThreadQueue{ ThreadCount };
			std::atomic<unsigned int> Index{ 0 };

			ThreadPool();
			~ThreadPool();

			void Run(unsigned int _i);
		public:

			static ThreadPool &get()
			{
				static ThreadPool instance;
				return instance;
			}
			// class _RET = std::result_of_t<_FUNC>,class _RET =std::result_of_t<_FUNC()>, 

 //_FUNC&& _func, ARGS&&...args)->std::future<decltype(_func(args...))>//  //
#ifdef MY_WRAPPER
			template<typename _FUNC, typename...ARGS >
			auto Async(Wrapper<_FUNC, ARGS... >  *_function)->std::future<typename Wrapper<_FUNC, ARGS... >::type> //Wrapper_Base::future<typename  Wrapper<_FUNC, ARGS... >::type>
			{// Accept arbitrary Function signature and arguments
				auto i = Index++;
				int K = 8;
				for (unsigned int n{ 0 }; n != ThreadCount * K; ++n) // K is Tunable 
				{
					if (ThreadQueue[static_cast<size_t>((i + n) % ThreadCount)].try_push(static_cast<Worker_Function*>(_function)))
					{
						return _function->ReturnValue.get_future();
					}
				}

				ThreadQueue[i % ThreadCount].push(static_cast<Worker_Function*>(_function));
				return _function->ReturnValue.get_future();
			}

#else
			template<typename _FUNC, typename...ARGS >
			auto Async(_FUNC&& _func, ARGS&&...args)->std::future<decltype(_func(args...))>//  //
			{// Accept arbitrary Function signature and arguments
				auto i = Index++;

				auto task_PTR = 
					std::make_shared<std::packaged_task<decltype(_func(args...))()>>
					(// Bind the argument and make a new packaged task to retrieve a future from on completion. 
						std::bind
						(
							std::forward<_FUNC>(_func),
							std::forward<ARGS>(args)...
						)
					);
		        //	if(_q[(i + n) % _count]
				std::function<void()> wrapper_func = [task_PTR]()
				{// Utilize std::functions type erasure to wrap the Task pointer
					(*task_PTR)();
				};


				int K = 8;	
				for (unsigned int n{ 0 }; n != ThreadCount * K; ++n) // K is Tunable 
				{
					if (ThreadQueue[static_cast<size_t>((i + n) % ThreadCount)].try_push(wrapper_func))
					{
						return task_PTR->get_future();
					}
				}
				 
			 	ThreadQueue[i % ThreadCount].push(wrapper_func);
				return  task_PTR->get_future();
			}   
#endif

		};
	}// End NS Threading
}// End NS Core 



int TestFunctionA();
int TestFunctionB(int _param);
float TestFunctionC(float _paramA, int _paramB);

std::string TestFunctionD(float _paramA, int _paramB);
std::vector<uint32_t> TestFunctionE(int _paramA);
std::vector<uint32_t> TestFunctionF(int _paramA);
std::vector<uint32_t> TestFunctionG(int _paramA);
std::vector<uint32_t> TestFunctionH(int _paramA);
std::vector<uint32_t> TestFunctionI(int _paramA);
std::vector<uint32_t> TestFunctionJ(int _paramA);

uint64_t TestCompile(std::vector<std::vector<uint32_t>> _input);
uint64_t Worker_TestFunction(size_t _count);

//
//pointer begin()
//{
//	return &Data[ReadPosition.location()];
//}
//pointer end()
//{
//	return &Data[WritePosition.location()];
//}
//
//	using iterator = rbIterator<_Ty>;
//iterator MyFirst() { return Data; }
//iterator MyLast() { return Data; }
//iterator MyEnd() { return MyLast(); }
// _NODISCARD iterator begin() noexcept
	// {	// return iterator for beginning of mutable sequence
	// 	return (iterator(this->_Myfirst(), _STD addressof(this->_Get_data())));
	// }



/*
		void make_Ready()//std::unique_lock<std::mutex>* _Lock)///, bool _At_thread_exit) Create a Defered signal so value is set when thread ends
		{
			//	_Has_stored_result = true;
		///if (_At_thread_exit) { // notify at thread exit
		///	_Cond._Register(*_Lock, &_Ready);
		///}
		///else { // notify immediately
			isReady = true;
			MutxCV.notify_all();
		///}
		}
		*/




		//type get()
		//{ // block until ready then return the stored result or
		//		// throw the stored exception
		//	//future _Local{ std::move(*this) };
		//	return type();// 0;//_STD move(_Local._Get_value());
		//}
		//std::future<std::invoke_result_t<_Func&, ARGS...>>& get_future()
		//{
		//	std::promise<std::invoke_result_t<_Func&, ARGS...>> result
		//}

		/*


			_State_manager& operator=(const _State_manager& _Other) { // assign from _Other
			_Copy_from(_Other);
			return *this;
		}

		_State_manager& operator=(_State_manager&& _Other) { // assign from rvalue _Other
			_Move_from(_Other);
			return *this;
		}

		_NODISCARD bool valid() const noexcept { // return status
			return _Assoc_state && !(_Get_only_once && _Assoc_state->_Already_retrieved());
		}

		void wait() const { // wait for signal
			if (!valid()) {
				_Throw_future_error(make_error_code(future_errc::no_state));
			}

			_Assoc_state->_Wait();
		}
			template <class _Clock, class _Dur>
		future_status wait_until(const chrono::time_point<_Clock, _Dur>& _Abs_time) const { // wait until time point
			if (!valid()) {
				_Throw_future_error(make_error_code(future_errc::no_state));
			}

			return _Assoc_state->_Wait_until(_Abs_time);
		}

		_Ty& _Get_value() const { // return the stored result or throw stored exception
			if (!valid()) {
				_Throw_future_error(make_error_code(future_errc::no_state));
			}

			return _Assoc_state->_Get_value(_Get_only_once);
		}

		void _Set_value(const _Ty& _Val, bool _Defer) { // store a result
			if (!valid()) {
				_Throw_future_error(make_error_code(future_errc::no_state));
			}

			_Assoc_state->_Set_value(_Val, _Defer);
		}

		void _Set_value(_Ty&& _Val, bool _Defer) { // store a result
			if (!valid()) {
				_Throw_future_error(make_error_code(future_errc::no_state));
			}

			_Assoc_state->_Set_value(_STD forward<_Ty>(_Val), _Defer);
		}
		   void _Abandon() { // abandon shared state
			if (_Assoc_state) {
				_Assoc_state->_Abandon();
			}
		}

		void _Set_exception(exception_ptr _Exc, bool _Defer) { // store a result
			if (!valid()) {
				_Throw_future_error(make_error_code(future_errc::no_state));
			}

			_Assoc_state->_Set_exception(_Exc, _Defer);
		}

		void _Swap(_State_manager& _Other) { // exchange with _Other
			_STD swap(_Assoc_state, _Other._Assoc_state);
		}
		*/

		//		        unique_lock<mutex> _Lock(_Mtx);
		//    _Maybe_run_deferred_function(_Lock);
		//    while (!_Ready) {
		//        _Cond.wait(_Lock);
		//    }
		/* Likely will need this later down the line */
	//template <>
	//class future<void>
	//{
	//	using type = std::void_t<>;//_Ty;
	//	//using reference_type = type&;
	//	//using pointer_type = _Ty*;
	//
	//	future() noexcept = default;
	//
	//	/* construct from rvalue future object noexcept*/
	//	future(future && _Other) : std::move(_Other) { }
	//
	//	/* assign from rvalue future object noexcept(put this back when everything is good to go)*/
	//	future& operator=(future && _Right) { memmove(this, _Right, sizeof(future));	return *this; }
	//	~future() noexcept = default;
	//
	//	/**/
	//	reference_type& get()
	//	{
	//		while (!isReady) {}
	//		return std::move(*Value);
	//	}
	//	/**/
	//	inline void set(reference_type _value)
	//	{/// maybe pass by value....
	//	//	Value = _value;
	//	//	isReady = true;
	//	}
	//
	//	void wait()
	//	{
	//		/*
	//		        unique_lock<mutex> _Lock(_Mtx);
	//    _Maybe_run_deferred_function(_Lock);
	//    while (!_Ready) {
	//        _Cond.wait(_Lock);
	//    }
	//		*/
	//		while (!isReady) {}
	//	}
	//	pointer_type Value = nullptr;
	//
	//	future(const future&) = delete;
	//	future& operator=(const future&) = delete;
	//};
		//virtual future<void>& get_future() = 0;

		//virtual void get_future() = 0;







	/*
	template<class _Ty>
	struct future
	{
		using type = _Ty;
		using pointer_type = _Ty*;

		/// using reference_type = type&; Removed because of possible void call to this function. That would result in invalid type so either overload
		/// This future Template with a <void> version or perhaps branch in our wrapper to never deal with the future if there is no return value anyway

		future() noexcept = default;
		~future() noexcept = default;

		/* construct from rvalue future object noexcept*/
		//future(future&& _Other)  {this = std::forward(_Other); } //std::move(_Other)

		/* assign from rvalue future object noexcept(put this back when everything is good to go)*/
		///future& operator=(future&& _Right) 
		///{ ERROR
		///	//memmove(*this, _Right, sizeof(future));	return *this; 
		///	*this = std::forward(_Right);
		///	return *this;
		///}

		/*reference_type
		type get()
		{
			//std::unique_lock<std::mutex> value_Lock(Mutx);
			while (!isReady) {}
			return std::move(*Value);
		}
		/*
		inline void set(type* _value)
		{/// maybe pass by value....reference_type
			Value = _value;
			make_Ready();
		}

		/* Wait until the stored function returns and we are able to aquire its return value
		void wait()
		{
		//	std::unique_lock<std::mutex> value_Lock(Mutx);
			while (!isReady)
			{
				//Mutx_CV.wait(value_Lock);
			}
			make_Ready();
		}
		/* Signal to our threads that our Value is ready to be retrieved
		void make_Ready()
		{
			TODO("Make This class non movable or assignable again currently commented out");
			isReady = true;
		///	Mutx_CV.notify_all();
		}

		bool isReady{ false };/// Just make this the CV but my hands are cold so lets get this shit done
		pointer_type Value = nullptr;
		///std::mutex Mutx;
		///std::condition_variable Mutx_CV;
		bool Retrieved{false};


		///RETURN THESE AND MAKE THIS NON COPYABLE AGAIN!!!
		///==================
		//future(const future&) = delete;
		//future& operator=(const future&) = delete;
	};


1:11 a, 11/29/2019
beer cans in my corner, area turned into liquor store, they walked through door and said shhhsh
woman took my coat

asking neighbors 
went to corner and it was to big

ev came back
broook came home, hadd dog with her

was slonr,// was alone
//everyones 
rbrtupmnr pm bsvsyopm//  2on
sy nrrt dypotrd// at? meet dypoytrd
twoman said shhhsh 
/*
went to the corner to hid
Cops in back when I went out there to leave
woman took my coat, my mom told me while looking out front window
could hear brooks music

*/

drove around town
was in school
couldnt remember my second class asked teacher
kids talking about artwork
cemetary 
lyyn was looking for me in town or something



//future<type> ReturnValue;
//future<type>& get_future()
//{
//	return ReturnValue;// std::move(ReturnValue);
//}
//	future<type> ReturnValue;
//virtual void operator()() override
//{
//	Invoke();
//}//	std::atomic<bool> isReady{ false };


*/
